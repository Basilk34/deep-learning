import streamlit as st
import tensorflow as tf
import numpy as np
import pickle
from tensorflow.keras.preprocessing.sequence import pad_sequences

# --- Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ---
max_len = 100  # ØªØ£ÙƒØ¯ Ø£Ù†Ù‡Ø§ Ù†ÙØ³ Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„ØªÙŠ Ø¯Ø±Ø¨Øª Ø¨Ù‡Ø§
labels = ['Extremely Negative', 'Negative', 'Neutral', 'Positive', 'Extremely Positive']

# --- ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØ§Ù„ØªÙˆÙƒÙ†ÙŠØ²Ø± ---
@st.cache_resource
def load_model_and_tokenizer():
    model = tf.keras.models.load_model('lstm_corona_model.h5')
    with open('tokenizer (1).pickle', 'rb') as f:
        tokenizer = pickle.load(f)
    return model, tokenizer

model, tokenizer = load_model_and_tokenizer()

# --- ÙˆØ§Ø¬Ù‡Ø© Streamlit ---
st.set_page_config(page_title="ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ÙŠÙˆÙ„", page_icon="ğŸ’¬")
st.title("ğŸ” ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ÙŠÙˆÙ„ ØªØ¬Ø§Ù‡ ÙƒÙˆØ±ÙˆÙ†Ø§ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… LSTM")

user_input = st.text_input("ğŸ“ Ø£Ø¯Ø®Ù„ ØªØºØ±ÙŠØ¯Ø© Ø£Ùˆ Ù†Øµ ØªØ­Ù„ÙŠÙ„:")

if user_input:
    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ ØªØ³Ù„Ø³Ù„ Ø±Ù‚Ù…ÙŠ
    seq = tokenizer.texts_to_sequences([user_input])
    padded = pad_sequences(seq, maxlen=max_len, padding='post', truncating='post')

    # Ø§Ù„ØªÙ†Ø¨Ø¤
    prediction = model.predict(padded)
    class_idx = np.argmax(prediction)
    confidence = np.max(prediction)

    # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªÙŠØ¬Ø©
    st.success(f"**Ø§Ù„ØªØµÙ†ÙŠÙ:** {labels[class_idx]}")
    st.info(f"**Ù†Ø³Ø¨Ø© Ø§Ù„Ø«Ù‚Ø©:** {confidence:.2f}")

from collections import Counter
import re

def extract_keywords(text, num_keywords=5):
    # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Øµ: Ø­Ø°Ù Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„ØªØ±Ù‚ÙŠÙ… ÙˆØ§Ù„Ø£Ø­Ø±Ù Ø§Ù„Ø®Ø§ØµØ©
    words = re.findall(r'\b\w+\b', text.lower())
    stopwords = set(['the', 'is', 'in', 'and', 'to', 'of', 'a', 'for', 'on', 'with', 'that', 'this'])  # Ù…Ù…ÙƒÙ† ØªÙˆØ³Ø¹Ù‡Ø§
    filtered_words = [w for w in words if w not in stopwords]
    most_common = Counter(filtered_words).most_common(num_keywords)
    return [word for word, count in most_common]

# ÙÙŠ ÙˆØ§Ø¬Ù‡Ø© Streamlit
keywords = extract_keywords(user_input)
if keywords:
    st.markdown("### ğŸ”‘ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© Ø§Ù„Ø£ÙƒØ«Ø± Ø¸Ù‡ÙˆØ±Ù‹Ø§:")
    st.write(", ".join(keywords))

