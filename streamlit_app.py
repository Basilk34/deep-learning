import streamlit as st
import tensorflow as tf
import numpy as np
import pickle
from tensorflow.keras.preprocessing.sequence import pad_sequences

# --- Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ---
max_len = 100  # ØªØ£ÙƒØ¯ Ø£Ù†Ù‡Ø§ Ù†ÙØ³ Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„ØªÙŠ Ø¯Ø±Ø¨Øª Ø¨Ù‡Ø§
labels = ['Extremely Negative', 'Negative', 'Neutral', 'Positive', 'Extremely Positive']
# --- ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØ§Ù„ØªÙˆÙƒÙ†ÙŠØ²Ø± ---
@st.cache_resource
def load_model_and_tokenizer():
    model = tf.keras.models.load_model('lstm_corona_model.h5')
    with open('tokenizer (1).pickle', 'rb') as f:
        tokenizer = pickle.load(f)
    return model, tokenizer

model, tokenizer = load_model_and_tokenizer()

# --- ÙˆØ§Ø¬Ù‡Ø© Streamlit ---
st.set_page_config(page_title="ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ÙŠÙˆÙ„", page_icon="ğŸ’¬")
st.title("ğŸ” ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ÙŠÙˆÙ„ ØªØ¬Ø§Ù‡ ÙƒÙˆØ±ÙˆÙ†Ø§ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… LSTM")

user_input = st.text_input("ğŸ“ Ø£Ø¯Ø®Ù„ ØªØºØ±ÙŠØ¯Ø© Ø£Ùˆ Ù†Øµ ØªØ­Ù„ÙŠÙ„:")

if user_input:
    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ ØªØ³Ù„Ø³Ù„ Ø±Ù‚Ù…ÙŠ
    seq = tokenizer.texts_to_sequences([user_input])
    padded = pad_sequences(seq, maxlen=max_len, padding='post', truncating='post')

    # Ø§Ù„ØªÙ†Ø¨Ø¤
    prediction = model.predict(padded)
    class_idx = np.argmax(prediction)
    confidence = np.max(prediction)

    # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªÙŠØ¬Ø©
    st.success(f"**Ø§Ù„ØªØµÙ†ÙŠÙ:** {labels[class_idx]}")
    st.info(f"**Ù†Ø³Ø¨Ø© Ø§Ù„Ø«Ù‚Ø©:** {confidence:.2f}")
