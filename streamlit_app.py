


    query = st.text_input("ğŸ” Ø§Ø¨Ø­Ø« Ø¯Ø§Ø®Ù„ Ø§Ù„Ù…Ù†Ø´ÙˆØ±Ø§Øª:")
    if query:
        results = [p for p in posts if query.lower() in p.lower()]
        if results:
            st.write("### âœ… Ø§Ù„Ù†ØªØ§Ø¦Ø¬:")
            for res in results:
                st.write(f"- {res}")
                seq = tokenizer.texts_to_sequences([res])
                padded = pad_sequences(seq, maxlen=10)
                pred = model.predict(padded, verbose=0)
                label = label_map[np.argmax(pred)]
                st.write(f"ğŸ§  Ø§Ù„ØªÙˆØ¬Ù‡: `{label}`")
        else:
            st.warning("ğŸš« Ù„Ø§ ØªÙˆØ¬Ø¯ Ù†ØªØ§Ø¦Ø¬ Ù…Ø·Ø§Ø¨Ù‚Ø©.")
