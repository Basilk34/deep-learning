import streamlit as st
st.set_page_config(page_title="ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ÙŠÙˆÙ„", page_icon="ğŸ’¬")

import tensorflow as tf
import numpy as np
import pickle
from tensorflow.keras.preprocessing.sequence import pad_sequences
from collections import Counter
import re
import datetime
import matplotlib.pyplot as plt

# --- Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ---
max_len = 100  # ØªØ£ÙƒØ¯ Ø£Ù†Ù‡Ø§ Ù†ÙØ³ Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„ØªÙŠ Ø¯Ø±Ø¨Øª Ø¨Ù‡Ø§
labels = ['Extremely Negative', 'Negative', 'Neutral', 'Positive', 'Extremely Positive']

# --- ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØ§Ù„ØªÙˆÙƒÙ†ÙŠØ²Ø± ---
@st.cache_resource
def load_model_and_tokenizer():
    model = tf.keras.models.load_model('lstm_corona_model.h5')
    with open('tokenizer (1).pickle', 'rb') as f:
        tokenizer = pickle.load(f)
    return model, tokenizer

model, tokenizer = load_model_and_tokenizer()

# --- Ø¯Ø§Ù„Ø© Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© ---
def extract_keywords(text, num_keywords=5):
    words = re.findall(r'\b\w+\b', text.lower())
    stopwords = set(['the', 'is', 'in', 'and', 'to', 'of', 'a', 'for', 'on', 'with', 'that', 'this'])
    filtered_words = [w for w in words if w not in stopwords]
    most_common = Counter(filtered_words).most_common(num_keywords)
    return most_common  # ØªØ±Ø¬Ø¹ Ù‚Ø§Ø¦Ù…Ø© Ù…Ù† tuples (ÙƒÙ„Ù…Ø©ØŒ ØªÙƒØ±Ø§Ø±)

# --- ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ ---
st.title("ğŸ” ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ÙŠÙˆÙ„ ØªØ¬Ø§Ù‡ ÙƒÙˆØ±ÙˆÙ†Ø§ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… LSTM")

# Ø£ÙˆÙ„Ø§Ù‹: Ø§Ø³Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙˆØ§Ù„ØªØ§Ø±ÙŠØ®
username = st.text_input("ğŸ‘¤ Ø£Ø¯Ø®Ù„ Ø§Ø³Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…:")
date = st.date_input("ğŸ“… Ø§Ø®ØªØ± Ø§Ù„ØªØ§Ø±ÙŠØ®:", datetime.date.today())

# ÙÙ‚Ø· Ø¥Ø°Ø§ ØªÙ… Ø¥Ø¯Ø®Ø§Ù„ Ø§Ø³Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù†Ø¹Ø±Ø¶ Ø®Ø§Ù†Ø© Ø§Ù„Ù†Øµ ÙˆØ²Ø± Ø§Ù„ØªØ­Ù„ÙŠÙ„
if username:
    user_input = st.text_area("ğŸ“ Ø£Ø¯Ø®Ù„ ØªØºØ±ÙŠØ¯Ø© Ø£Ùˆ Ù†Øµ ØªØ­Ù„ÙŠÙ„:")
    if st.button("ØªØ­Ù„ÙŠÙ„"):
        if not user_input.strip():
            st.warning("Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø¯Ø®Ø§Ù„ Ù†Øµ Ù„Ù„ØªØ­Ù„ÙŠÙ„!")
        else:
            # Ø§Ù„ØªÙ†Ø¨Ø¤
            seq = tokenizer.texts_to_sequences([user_input])
            padded = pad_sequences(seq, maxlen=max_len, padding='post', truncating='post')
            prediction = model.predict(padded)
            class_idx = np.argmax(prediction)
            confidence = np.max(prediction)

            # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
            st.success(f"**Ø§Ø³Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…:** {username}")
            st.success(f"**Ø§Ù„ØªØ§Ø±ÙŠØ®:** {date}")
            st.success(f"**Ø§Ù„ØªØµÙ†ÙŠÙ:** {labels[class_idx]}")
            st.info(f"**Ù†Ø³Ø¨Ø© Ø§Ù„Ø«Ù‚Ø©:** {confidence:.2f}")

            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©
            keywords = extract_keywords(user_input)
            if keywords:
                st.markdown("### ğŸ”‘ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© Ø§Ù„Ø£ÙƒØ«Ø± Ø¸Ù‡ÙˆØ±Ù‹Ø§:")
                words, counts = zip(*keywords)
                st.write(", ".join(words))

                # Ø±Ø³Ù… Ø¨ÙŠØ§Ù†ÙŠ
                fig, ax = plt.subplots()
                ax.bar(words, counts, color='skyblue')
                ax.set_ylabel('Ø¹Ø¯Ø¯ Ø§Ù„ØªÙƒØ±Ø§Ø±')
                ax.set_title('Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©')
                st.pyplot(fig)
else:
    st.info("Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø¯Ø®Ø§Ù„ Ø§Ø³Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù„Ù„Ø¨Ø¯Ø¡.")

import streamlit as st
import tensorflow as tf
import numpy as np
from tensorflow.keras.preprocessing import image
import gdown
import os
from PIL import Image

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª
IMG_SIZE = 224
MODEL_PATH = "flower_model.h5"
MODEL_URL = "https://drive.google.com/uc?id=1oYuyEpzubzQ2Ph67l3ZKvDjQYCcLwQjY"

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ù† Google Drive Ù„Ùˆ Ù…Ø´ Ù…ÙˆØ¬ÙˆØ¯ Ù…Ø­Ù„ÙŠØ§Ù‹
if not os.path.exists(MODEL_PATH):
    with st.spinner("Downloading model..."):
        gdown.download(MODEL_URL, MODEL_PATH, quiet=False)

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
model = tf.keras.models.load_model(MODEL_PATH)

# Ø¯Ø§Ù„Ø© Ø§Ù„ØªÙ†Ø¨Ø¤
def predict_flower(img):
    img = img.resize((IMG_SIZE, IMG_SIZE))
    img_array = image.img_to_array(img) / 255.0
    img_array = np.expand_dims(img_array, axis=0)
    prediction = model.predict(img_array)
    class_labels = list(train_generator.class_indices.keys()) if 'train_generator' in globals() else ['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']
    predicted_class = class_labels[np.argmax(prediction)]
    confidence = np.max(prediction)
    return predicted_class, confidence

# Ø¹Ù†ÙˆØ§Ù† Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
st.title("Flower Classification with VGG16")

# Ø±ÙØ¹ ØµÙˆØ±Ø© Ù…Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
uploaded_file = st.file_uploader("Upload an image of a flower", type=["jpg", "jpeg", "png"])

if uploaded_file is not None:
    img = Image.open(uploaded_file)
    st.image(img, caption='Uploaded Image', use_column_width=True)
    predicted_class, confidence = predict_flower(img)
    st.write(f"Prediction: **{predicted_class}**")
    st.write(f"Confidence: {confidence:.2f}")

else:
    st.write("Please upload an image to classify.")
